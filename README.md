# Netflix-Azure-Data-Engineer-Project

Developed end-to-end ETL pipeline that transforms Netflix data from raw formats into high-quality, structured data, ready for advanced analyticsâ€”leveraging the Medallion Architecture and Delta Lake. ğŸ’¡

ğŸ”·ğğ«ğ¨ğ§ğ³ğ ğ‹ğšğ²ğğ« â€“ ğ‘ğšğ° ğƒğšğ­ğš ğˆğ§ğ ğğ¬ğ­ğ¢ğ¨ğ§:
Used Azure Data Factory to ingest data from multiple sources (CSV, REST API, GitHub) into Azure Data Lake Storage Gen2 (ğ€ğƒğ‹ğ’ ğ†ğğ§ğŸ).
Designed a parameterized pipeline to handle multiple files, optimizing ingestion based on file size and activity.

ğŸ”¶ğ’ğ¢ğ¥ğ¯ğğ« ğ‹ğšğ²ğğ« â€“ ğƒğšğ­ğš ğ“ğ«ğšğ§ğ¬ğŸğ¨ğ«ğ¦ğšğ­ğ¢ğ¨ğ§:
Utilized Azure Databricks and PySpark for data cleansing and transformation.
Connected ADB to ADLS via Azure Access Connector and implemented Unity Catalog for metadata management and data governance.
Stored the cleaned data back into the Silver Layer in Parquet format, ready for aggregation.

ğŸŸ¡ğ†ğ¨ğ¥ğ ğ‹ğšğ²ğğ« â€“ ğ‘ğğšğğ² ğŸğ¨ğ« ğ€ğ§ğšğ¥ğ²ğ­ğ¢ğœğ¬:
Aggregated and optimized data stored in Delta Lake format, ensuring transactional consistency and enabling time travel for historical analysis.
Created Delta Tables and used SQL in Databricks for efficient querying.
Enabled schema evolution to handle changes in incoming data seamlessly, making the dataset analytics-ready.

ğŸ’¡ğ“ğğœğ¡ğ§ğ¨ğ¥ğ¨ğ ğ¢ğğ¬ ğ”ğ¬ğğ:
âœ… Azure Data Lake Storage Gen2 (ADLS Gen2)
âœ… Azure Data Factory (Dynamic Pipeline)
âœ… Azure Databricks
âœ… Azure Access Connector
âœ… PySpark
âœ… Microsoft Entra ID
